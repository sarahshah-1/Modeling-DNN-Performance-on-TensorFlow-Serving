{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WI-3O9eSg-D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D8jo67Yd7Jp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/payload-core-mem-full-dataset-train-3-quarter-3.csv')\n",
        "\n",
        "# df = og_df[((og_df['ml_model'] != 'mnist') & ((og_df['rate'] <= 25) | ((og_df['rate'] >= 45) & (og_df['rate'] <= 65)) | (og_df['rate'] >= 85))) | ((og_df['ml_model'] == 'mnist') & ((og_df['rate'] <= 135) | ((og_df['rate'] >= 225) & (og_df['rate'] <= 295)) | (og_df['rate'] >= 405)))]\n",
        "# df = og_df[((og_df['ml_model'] != 'mnist') & ((og_df['rate'] <= 45) | (og_df['rate'] >= 85))) | ((og_df['ml_model'] == 'mnist') & ((og_df['rate'] <= 225) | (og_df['rate'] >= 445)))]\n",
        "# df = og_df[((og_df['ml_model'] != 'mnist') & ((og_df['rate'] <= 25) | (og_df['rate'] >= 65))) | ((og_df['ml_model'] == 'mnist') & ((og_df['rate'] <= 135) | (og_df['rate'] >= 345)))]\n",
        "\n",
        "selected_columns = ['rate','memory','payload_instance','cores','ml_model']\n",
        "\n",
        "\n",
        "X = df[selected_columns]\n",
        "y = df[['response_time']]\n",
        "string_encoder = preprocessing.LabelEncoder()\n",
        "X['ml_model'] = string_encoder.fit_transform(X['ml_model'])\n",
        "file_prefix = 'predict_response_time_payload_3-3-3_combo_errorfree'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MGqeF1aYTJR"
      },
      "outputs": [],
      "source": [
        "df.plot(x='rate', y=['response_time'], style='o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ75__vcSLPv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LR with Polynomial Features"
      ],
      "metadata": {
        "id": "qwVhv_t9ULJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=4)\n",
        "\n",
        "X_poly_train = poly_features.fit_transform(X_train)\n",
        "X_poly_test = poly_features.fit_transform(X_test)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "lin_reg.fit(X_poly_train, y_train)\n",
        "\n",
        "y_pred = lin_reg.predict(X_poly_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())"
      ],
      "metadata": {
        "id": "y_CNo4XnUO1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfXG_RePeYv4"
      },
      "source": [
        "##Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dB40_mDeDLI"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjRSVLsAeONQ"
      },
      "outputs": [],
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwZ3AsP6h0f5"
      },
      "outputs": [],
      "source": [
        "importances = regressor.feature_importances_\n",
        "forest_importances = pd.Series(importances, index=selected_columns)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy31hyx_0go_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 50)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "pprint(random_grid)\n",
        "\n",
        "new_reg = RandomForestRegressor()\n",
        "regressor_random = RandomizedSearchCV(estimator = new_reg, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "regressor_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK1YVIh9snbI"
      },
      "outputs": [],
      "source": [
        "y_pred = regressor_random.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'rf_random.csv')\n",
        "regressor_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qKItRAZrTGQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [None, 10, 20, 60, 80, 90],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'min_samples_leaf': [1, 2, 4, 5],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'n_estimators': [90, 480, 180, 40, 350]\n",
        "}\n",
        "grid_reg = RandomForestRegressor()\n",
        "grid_search = GridSearchCV(estimator = grid_reg, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DilH37AN3kdN"
      },
      "outputs": [],
      "source": [
        "y_pred = grid_search.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'rf_gridsearch.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox_uQzJgGtEd"
      },
      "outputs": [],
      "source": [
        "sns.distplot(abs(y_test-predicted_df)/y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMP0lSZVIvV5"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_test,predicted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxLegJnrVDwq"
      },
      "outputs": [],
      "source": [
        "grid_search_best_model = RandomForestRegressor(bootstrap=True,max_depth=90,max_features='auto', \\\n",
        "                                               min_samples_leaf=2,min_samples_split=2,n_estimators=90)\n",
        "grid_search_best_model.fit(X_train, y_train)\n",
        "importances = grid_search_best_model.feature_importances_\n",
        "forest_importances = pd.Series(importances, index=selected_columns)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8ToGG0nevNO"
      },
      "outputs": [],
      "source": [
        "############ new test file ############\n",
        "\n",
        "test_10c = pd.read_csv('/content/payload-core-mem-full-dataset-test-12-full-single.csv')\n",
        "# test_10c = og_test_10c[(og_test_10c['ml_model'] != 'mnist') & (og_test_10c['ml_model'] != 'bert')]\n",
        "test_10c.plot(x='rate', y=['response_time'], style='o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLUfCSHBNu-R"
      },
      "outputs": [],
      "source": [
        "########## tests with default regressor #########\n",
        "\n",
        "test_data = test_10c[selected_columns]\n",
        "string_encoder = preprocessing.LabelEncoder()\n",
        "test_data['ml_model'] = string_encoder.fit_transform(test_data['ml_model'])\n",
        "test_data = test_data.dropna(axis=0)\n",
        "test_labels = test_10c[['response_time']]\n",
        "test_labels = test_labels.dropna(axis=0)\n",
        "predicted_labels = regressor.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['rate'] = test_data['rate']\n",
        "errors['cores'] = test_data['cores']\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv('rf_default_unseen.csv')\n",
        "regressor.get_params()"
      ],
      "metadata": {
        "id": "zpfsGekH4Miv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K8qq1PdepUG"
      },
      "outputs": [],
      "source": [
        "########## tests with random regressor #########\n",
        "\n",
        "test_data = test_10c[selected_columns]\n",
        "string_encoder = preprocessing.LabelEncoder()\n",
        "test_data['ml_model'] = string_encoder.fit_transform(test_data['ml_model'])\n",
        "test_labels = test_10c[['cores']]\n",
        "test_labels = test_labels.dropna(axis=0)\n",
        "predicted_labels = regressor_random.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['cores']\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['rate'] = test_data['rate']\n",
        "errors['ml_model'] = test_data['ml_model']\n",
        "errors['cores'] = test_data['cores']\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'rf_randomsearch.csv')\n",
        "regressor.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeKFrJOhKEXr"
      },
      "source": [
        "## Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ts0dVFsKDze"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor(random_state=0)\n",
        "dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taIQxwaGR0jk"
      },
      "outputs": [],
      "source": [
        "y_pred = dt.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'dt.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN-RW38jkFW5"
      },
      "outputs": [],
      "source": [
        "test_data = test_10c[selected_columns]\n",
        "string_encoder = preprocessing.LabelEncoder()\n",
        "test_data['ml_model'] = string_encoder.fit_transform(test_data['ml_model'])\n",
        "# test_data = test_data.dropna(axis=0)\n",
        "test_labels = test_10c[['response_time']]\n",
        "test_labels = test_labels.dropna(axis=0)\n",
        "predicted_labels = dt.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['rate'] = test_data['rate']\n",
        "errors['ml_model'] = test_data['ml_model']\n",
        "errors['cores'] = test_data['cores']\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv('dt_default_unseen.csv')\n",
        "errors['error']\n",
        "dt.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9xxmDMlJZDY"
      },
      "outputs": [],
      "source": [
        "sns.distplot(y_test-predicted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsRGbcXrJh_0"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_test,predicted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slVzG4f7J60x"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters range intialization for tuning \n",
        "\n",
        "parameters={\"splitter\":[\"best\",\"random\"],\n",
        "            \"max_depth\" : [None, 1,5,10,15],\n",
        "            \"min_samples_leaf\":[1,2,3,4,5,7,9,11],\n",
        "            \"min_samples_split\":[2,5,10,15],\n",
        "            \"min_weight_fraction_leaf\":[0.1,0.3,0.5],\n",
        "            \"max_features\":[\"auto\",\"log2\",\"sqrt\",None] }\n",
        "tuning_model=GridSearchCV(dt,param_grid=parameters,scoring='neg_mean_squared_error',cv=3,verbose=3)\n",
        "tuning_model.fit(X_train,y_train)\n",
        "tuning_model.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqAJMtn2MrnB"
      },
      "outputs": [],
      "source": [
        "tuned_hyper_model= DecisionTreeRegressor(max_depth=None,max_features='auto',min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.1,splitter='best')\n",
        "tuned_hyper_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkEcqVYZZmeL"
      },
      "outputs": [],
      "source": [
        "y_pred = tuned_hyper_model.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'dt_gridsearch.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L69byd8iWL48"
      },
      "outputs": [],
      "source": [
        "test_data = test_10c[selected_columns]\n",
        "string_encoder = preprocessing.LabelEncoder()\n",
        "test_data['ml_model'] = string_encoder.fit_transform(test_data['ml_model'])\n",
        "test_data = test_data.dropna(axis=0)\n",
        "test_labels = test_10c[['response_time']]\n",
        "test_labels = test_labels.dropna(axis=0)\n",
        "predicted_labels = tuned_hyper_model.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'dt_gridsearch_unseen.csv')\n",
        "\n",
        "errors['error'].mean()\n",
        "errors['error'].count()\n",
        "\n",
        "tuned_hyper_model.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MezpxrZjbLvV"
      },
      "source": [
        "##Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEaXxFBzbObO"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "rr = Ridge(alpha=0.01)\n",
        "rr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXEHQebIcWc0"
      },
      "outputs": [],
      "source": [
        "y_pred = rr.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALQESkYgiIjm"
      },
      "outputs": [],
      "source": [
        "predicted_labels = rr.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'rr_default.csv')\n",
        "\n",
        "errors['error'].mean()\n",
        "errors['error'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39qNx_wtdb14"
      },
      "source": [
        "##Elastic Net Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjz0hhuYdpdH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "model_enet = ElasticNet(alpha = 0.01)\n",
        "model_enet.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wq2Lw1Zd60H"
      },
      "outputs": [],
      "source": [
        "y_pred = model_enet.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz45zp3wiSoK"
      },
      "outputs": [],
      "source": [
        "predicted_labels = model_enet.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'en_default.csv')\n",
        "\n",
        "errors['error'].mean()\n",
        "errors['error'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d0FbB_WjS8t"
      },
      "source": [
        "## Support Vector Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNzBGa0UjYkP"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "svm_regressor = SVR(kernel='rbf')\n",
        "svm_regressor.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwDw_ES_jhhp"
      },
      "outputs": [],
      "source": [
        "y_pred = svm_regressor.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'rr_default.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoebi_mMiWuw"
      },
      "outputs": [],
      "source": [
        "predicted_labels = svm_regressor.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'svm_default.csv')\n",
        "errors['error'].mean()\n",
        "errors['error'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaboost Algorithms"
      ],
      "metadata": {
        "id": "cIhwfBRaLfGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "ada_regr = AdaBoostRegressor(random_state=0, n_estimators=50)\n",
        "ada_regr.fit(X_train,y_train)\n",
        "y_pred = ada_regr.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())"
      ],
      "metadata": {
        "id": "_RzGZQXvFbrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = ada_regr.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'ad_default.csv')\n",
        "errors['error'].mean()\n",
        "errors['error'].count()"
      ],
      "metadata": {
        "id": "UWlXALLcIIaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Algorithms"
      ],
      "metadata": {
        "id": "olxhYq6rLaa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "grad_reg = GradientBoostingRegressor(random_state=0)\n",
        "grad_reg.fit(X_train,y_train)\n",
        "y_pred = grad_reg.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())"
      ],
      "metadata": {
        "id": "ZyGWmgsiKuIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = grad_reg.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'gb_default.csv')\n",
        "errors['error'].mean()\n",
        "errors['error'].count()"
      ],
      "metadata": {
        "id": "FbqEuCzgLG7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extreme Gradient Boosting"
      ],
      "metadata": {
        "id": "QZFom9VCLj2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor \n",
        "xgb_reg = XGBRegressor(objective ='reg:linear',\n",
        "                  n_estimators = 10, seed = 123)\n",
        "xgb_reg.fit(X_train,y_train)\n",
        "y_pred = xgb_reg.predict(X_test)\n",
        "predicted_df = pd.DataFrame(y_pred)\n",
        "predicted_df.columns = ['response_time']\n",
        "errors = pd.concat([predicted_df, y_test.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())"
      ],
      "metadata": {
        "id": "vqaHP4kjLZbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = xgb_reg.predict(test_data)\n",
        "predicted_label_df = pd.DataFrame(predicted_labels)\n",
        "predicted_label_df.columns = ['response_time']\n",
        "\n",
        "errors = pd.concat([predicted_label_df, test_labels.reset_index(drop=True)], keys=['predicted', 'actual'], axis=1)\n",
        "errors['error'] = (((errors['predicted'] - errors['actual']).abs())/errors['actual'])*100\n",
        "print('Average Relative Error = ', errors['error'].mean())\n",
        "errors.to_csv(file_prefix+'xgb_default.csv')\n",
        "errors['error'].mean()\n",
        "errors['error'].count()"
      ],
      "metadata": {
        "id": "VG5tItKEMUlQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}